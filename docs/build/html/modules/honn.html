<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pygho.honn package &mdash; PyGHO 0.0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=d45e8c67"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="pygho.hodata package" href="hodata.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PyGHO
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/introduction.html">Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="backend.html">pygho.backend package</a></li>
<li class="toctree-l1"><a class="reference internal" href="hodata.html">pygho.hodata package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">pygho.honn package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.honn.Conv">pygho.honn.Conv module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.Conv.DSSGNNConv"><code class="docutils literal notranslate"><span class="pre">DSSGNNConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.Conv.DSSGNNConv.forward"><code class="docutils literal notranslate"><span class="pre">DSSGNNConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.Conv.GNNAKConv"><code class="docutils literal notranslate"><span class="pre">GNNAKConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.Conv.GNNAKConv.forward"><code class="docutils literal notranslate"><span class="pre">GNNAKConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.Conv.I2Conv"><code class="docutils literal notranslate"><span class="pre">I2Conv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.Conv.I2Conv.forward"><code class="docutils literal notranslate"><span class="pre">I2Conv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.Conv.NGNNConv"><code class="docutils literal notranslate"><span class="pre">NGNNConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.Conv.NGNNConv.forward"><code class="docutils literal notranslate"><span class="pre">NGNNConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.Conv.PPGNConv"><code class="docutils literal notranslate"><span class="pre">PPGNConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.Conv.PPGNConv.forward"><code class="docutils literal notranslate"><span class="pre">PPGNConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.Conv.SSWLConv"><code class="docutils literal notranslate"><span class="pre">SSWLConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.Conv.SSWLConv.forward"><code class="docutils literal notranslate"><span class="pre">SSWLConv.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.Conv.SUNConv"><code class="docutils literal notranslate"><span class="pre">SUNConv</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.Conv.SUNConv.forward"><code class="docutils literal notranslate"><span class="pre">SUNConv.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.honn.MaOperator">pygho.honn.MaOperator module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.Op2FWL"><code class="docutils literal notranslate"><span class="pre">Op2FWL</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.Op2FWL.forward"><code class="docutils literal notranslate"><span class="pre">Op2FWL.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpDiag"><code class="docutils literal notranslate"><span class="pre">OpDiag</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpDiag.forward"><code class="docutils literal notranslate"><span class="pre">OpDiag.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpDiag2D"><code class="docutils literal notranslate"><span class="pre">OpDiag2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpDiag2D.forward"><code class="docutils literal notranslate"><span class="pre">OpDiag2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassing"><code class="docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassing.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassing.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassingCrossSubg2D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingCrossSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassingCrossSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingCrossSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg2D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg3D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg3D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg3D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpNodeMessagePassing"><code class="docutils literal notranslate"><span class="pre">OpNodeMessagePassing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpNodeMessagePassing.forward"><code class="docutils literal notranslate"><span class="pre">OpNodeMessagePassing.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpPooling"><code class="docutils literal notranslate"><span class="pre">OpPooling</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpPooling.forward"><code class="docutils literal notranslate"><span class="pre">OpPooling.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpPoolingCrossSubg2D"><code class="docutils literal notranslate"><span class="pre">OpPoolingCrossSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpPoolingCrossSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingCrossSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpPoolingSubg2D"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpPoolingSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpPoolingSubg3D"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpPoolingSubg3D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg3D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassing"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassing.forward"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassing.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassingCrossSubg2D"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassingCrossSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassingCrossSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassingCrossSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg2D"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassingOnSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassingOnSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg3D"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassingOnSubg3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg3D.forward"><code class="docutils literal notranslate"><span class="pre">OpSpMessagePassingOnSubg3D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpNodeMessagePassing"><code class="docutils literal notranslate"><span class="pre">OpSpNodeMessagePassing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpSpNodeMessagePassing.forward"><code class="docutils literal notranslate"><span class="pre">OpSpNodeMessagePassing.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpUnpooling"><code class="docutils literal notranslate"><span class="pre">OpUnpooling</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.MaOperator.OpUnpooling.forward"><code class="docutils literal notranslate"><span class="pre">OpUnpooling.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpUnpoolingRootNodes2D"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingRootNodes2D</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.MaOperator.OpUnpoolingSubgNodes2D"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingSubgNodes2D</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.honn.SpOperator">pygho.honn.SpOperator module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.Op2FWL"><code class="docutils literal notranslate"><span class="pre">Op2FWL</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.Op2FWL.forward"><code class="docutils literal notranslate"><span class="pre">Op2FWL.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpDiag"><code class="docutils literal notranslate"><span class="pre">OpDiag</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpDiag.forward"><code class="docutils literal notranslate"><span class="pre">OpDiag.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpDiag2D"><code class="docutils literal notranslate"><span class="pre">OpDiag2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpDiag2D.forward"><code class="docutils literal notranslate"><span class="pre">OpDiag2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassing"><code class="docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassing.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassing.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassingCrossSubg2D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingCrossSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassingCrossSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingCrossSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg2D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg3D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg3D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg3D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpNodeMessagePassing"><code class="docutils literal notranslate"><span class="pre">OpNodeMessagePassing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpNodeMessagePassing.forward"><code class="docutils literal notranslate"><span class="pre">OpNodeMessagePassing.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpPooling"><code class="docutils literal notranslate"><span class="pre">OpPooling</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpPooling.forward"><code class="docutils literal notranslate"><span class="pre">OpPooling.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpPoolingCrossSubg2D"><code class="docutils literal notranslate"><span class="pre">OpPoolingCrossSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpPoolingCrossSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingCrossSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpPoolingSubg2D"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpPoolingSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpPoolingSubg3D"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpPoolingSubg3D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg3D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpUnpooling"><code class="docutils literal notranslate"><span class="pre">OpUnpooling</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.SpOperator.OpUnpooling.forward"><code class="docutils literal notranslate"><span class="pre">OpUnpooling.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpUnpoolingRootNodes2D"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingRootNodes2D</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.OpUnpoolingSubgNodes2D"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingSubgNodes2D</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.SpOperator.parse_precomputekey"><code class="docutils literal notranslate"><span class="pre">parse_precomputekey()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.honn.TensorOp">pygho.honn.TensorOp module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.Op2FWL"><code class="docutils literal notranslate"><span class="pre">Op2FWL</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.Op2FWL.forward"><code class="docutils literal notranslate"><span class="pre">Op2FWL.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpDiag2D"><code class="docutils literal notranslate"><span class="pre">OpDiag2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpDiag2D.forward"><code class="docutils literal notranslate"><span class="pre">OpDiag2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpMessagePassingCrossSubg2D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingCrossSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpMessagePassingCrossSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingCrossSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg2D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg3D"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg3D.forward"><code class="docutils literal notranslate"><span class="pre">OpMessagePassingOnSubg3D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpNodeMessagePassing"><code class="docutils literal notranslate"><span class="pre">OpNodeMessagePassing</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpNodeMessagePassing.forward"><code class="docutils literal notranslate"><span class="pre">OpNodeMessagePassing.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpPoolingCrossSubg2D"><code class="docutils literal notranslate"><span class="pre">OpPoolingCrossSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpPoolingCrossSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingCrossSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpPoolingSubg2D"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpPoolingSubg2D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpPoolingSubg3D"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpPoolingSubg3D.forward"><code class="docutils literal notranslate"><span class="pre">OpPoolingSubg3D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpUnpoolingRootNodes2D"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingRootNodes2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpUnpoolingRootNodes2D.forward"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingRootNodes2D.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.TensorOp.OpUnpoolingSubgNodes2D"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingSubgNodes2D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.TensorOp.OpUnpoolingSubgNodes2D.forward"><code class="docutils literal notranslate"><span class="pre">OpUnpoolingSubgNodes2D.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.honn.utils">pygho.honn.utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.utils.BatchNorm"><code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.utils.BatchNorm.forward"><code class="docutils literal notranslate"><span class="pre">BatchNorm.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.utils.LayerNorm"><code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.utils.LayerNorm.forward"><code class="docutils literal notranslate"><span class="pre">LayerNorm.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.utils.MLP"><code class="docutils literal notranslate"><span class="pre">MLP</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.utils.MLP.forward"><code class="docutils literal notranslate"><span class="pre">MLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.utils.NoneNorm"><code class="docutils literal notranslate"><span class="pre">NoneNorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.utils.NoneNorm.forward"><code class="docutils literal notranslate"><span class="pre">NoneNorm.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.honn.utils.NormMomentumScheduler"><code class="docutils literal notranslate"><span class="pre">NormMomentumScheduler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.honn.utils.NormMomentumScheduler.step"><code class="docutils literal notranslate"><span class="pre">NormMomentumScheduler.step()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.honn">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyGHO</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">pygho.honn package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/modules/honn.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pygho-honn-package">
<h1>pygho.honn package<a class="headerlink" href="#pygho-honn-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-pygho.honn.Conv">
<span id="pygho-honn-conv-module"></span><h2>pygho.honn.Conv module<a class="headerlink" href="#module-pygho.honn.Conv" title="Link to this heading"></a></h2>
<p>Representative GNN layers built upon message passing operations.
For all module, A means adjacency matrix, X means tuple representation 
mode SS means sparse adjacency and sparse X, SD means sparse adjacency and dense X, DD means dense adjacency and dense X.
datadict contains precomputation results.</p>
<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.Conv.DSSGNNConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.Conv.</span></span><span class="sig-name descname"><span class="pre">DSSGNNConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr_subg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr_global</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#DSSGNNConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.DSSGNNConv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the DSSGNNConv layer based on the paper “Equivariant subgraph aggregation networks” by Beatrice Bevilacqua et al., ICLR 2022.
This layer performs message passing on 2D subgraph representations with subgraph pooling.</p>
<p>Args:</p>
<ul class="simple">
<li><p>indim (int): Input feature dimension.</p></li>
<li><p>outdim (int): Output feature dimension.</p></li>
<li><p>aggr_subg (str): Aggregation method for message passing within subgraphs (e.g., “sum”).</p></li>
<li><p>aggr_global (str): Aggregation method for message passing in the global context (e.g., “sum”).</p></li>
<li><p>pool (str): Pooling method (e.g., “mean”).</p></li>
<li><p>mode (str): Mode for specifying tensor types (e.g., “SS” for sparse adjacency and sparse X).</p></li>
<li><p>mlp (dict): Parameters for the MLP layer.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[SparseTensor, MaskedTensor], datadict: dict) -&gt; Union[SparseTensor, MaskedTensor]:
Forward pass of the DSSGNNConv layer.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.Conv.DSSGNNConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#DSSGNNConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.DSSGNNConv.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.Conv.GNNAKConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.Conv.</span></span><span class="sig-name descname"><span class="pre">GNNAKConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#GNNAKConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.GNNAKConv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the GNNAKConv layer based on the paper “From stars to subgraphs: Uplifting any GNN with local structure awareness” by Lingxiao Zhao et al., ICLR 2022.
This layer performs message passing on 2D subgraph representations with subgraph pooling and cross-subgraph pooling.</p>
<p>Args:</p>
<ul class="simple">
<li><p>indim (int): Input feature dimension.</p></li>
<li><p>outdim (int): Output feature dimension.</p></li>
<li><p>aggr (str): Aggregation method for message passing (e.g., “sum”).</p></li>
<li><p>pool (str): Pooling method (e.g., “mean”).</p></li>
<li><p>mode (str): Mode for specifying tensor types (e.g., “SS” for sparse adjacency and sparse X).</p></li>
<li><p>mlp0 (dict): Parameters for the first MLP layer.</p></li>
<li><p>mlp1 (dict): Parameters for the second MLP layer.</p></li>
<li><p>ctx (bool): Whether to include context information.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[SparseTensor, MaskedTensor], datadict: dict) -&gt; Union[SparseTensor, MaskedTensor]:
Forward pass of the GNNAKConv layer.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.Conv.GNNAKConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#GNNAKConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.GNNAKConv.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.Conv.I2Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.Conv.</span></span><span class="sig-name descname"><span class="pre">I2Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#I2Conv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.I2Conv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the I2Conv layer based on the paper “Boosting the cycle counting power of graph neural networks with I2-GNNs” by Yinan Huang et al., ICLR 2023.
This layer performs message passing on 3D subgraph representations.</p>
<p>Args:</p>
<ul class="simple">
<li><p>indim (int): Input feature dimension.</p></li>
<li><p>outdim (int): Output feature dimension.</p></li>
<li><p>aggr (str): Aggregation method for message passing (e.g., “sum”).</p></li>
<li><p>mode (str): Mode for specifying tensor types (e.g., “SS” for sparse adjacency and sparse X).</p></li>
<li><p>mlp (dict): Parameters for the MLP layer.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[SparseTensor, MaskedTensor], datadict: dict) -&gt; Union[SparseTensor, MaskedTensor]:
Forward pass of the I2Conv layer.</p></li>
</ul>
<p>Notes:
- This layer is based on the I2-GNN paper and performs message passing on 3D subgraph representations.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.Conv.I2Conv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#I2Conv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.I2Conv.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.Conv.NGNNConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.Conv.</span></span><span class="sig-name descname"><span class="pre">NGNNConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#NGNNConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.NGNNConv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the NGNNConv layer based on the paper “Nested Graph Neural Networks” by Muhan Zhang and Pan Li, NeurIPS 2021.
This layer performs message passing on 2D subgraph representations.</p>
<p>Args:</p>
<ul class="simple">
<li><p>indim (int): Input feature dimension.</p></li>
<li><p>outdim (int): Output feature dimension.</p></li>
<li><p>aggr (str): Aggregation method for message passing (e.g., “sum”).</p></li>
<li><p>mode (str): Mode for specifying tensor types (e.g., “SS” for sparse adjacency and sparse X).</p></li>
<li><p>mlp (dict): Parameters for the MLP layer.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[SparseTensor, MaskedTensor], datadict: dict) -&gt; Union[SparseTensor, MaskedTensor]:
Forward pass of the NGNNConv layer.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.Conv.NGNNConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#NGNNConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.NGNNConv.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.Conv.PPGNConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.Conv.</span></span><span class="sig-name descname"><span class="pre">PPGNConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#PPGNConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.PPGNConv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the PPGNConv layer based on the paper “Provably powerful graph networks” by Haggai Maron et al., NeurIPS 2019.
This layer performs message passing with power-sum pooling on 2D subgraph representations.</p>
<p>Args:</p>
<ul class="simple">
<li><p>indim (int): Input feature dimension.</p></li>
<li><p>outdim (int): Output feature dimension.</p></li>
<li><p>aggr (str): Aggregation method for message passing (e.g., “sum”).</p></li>
<li><p>mode (str): Mode for specifying tensor types (e.g., “SS” for sparse adjacency and sparse X).</p></li>
<li><p>mlp (dict): Parameters for the MLP layers.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[SparseTensor, MaskedTensor], datadict: dict) -&gt; Union[SparseTensor, MaskedTensor]:
Forward pass of the PPGNConv layer.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.Conv.PPGNConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#PPGNConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.PPGNConv.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.Conv.SSWLConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.Conv.</span></span><span class="sig-name descname"><span class="pre">SSWLConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#SSWLConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.SSWLConv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the SSWLConv layer based on the paper “A complete expressiveness hierarchy for subgraph GNNs via subgraph Weisfeiler-Lehman tests” by Bohang Zhang et al., ICML 2023.
This layer performs message passing on 2D subgraph representations and cross-subgraph pooling.</p>
<p>Args:</p>
<ul class="simple">
<li><p>indim (int): Input feature dimension.</p></li>
<li><p>outdim (int): Output feature dimension.</p></li>
<li><p>aggr (str): Aggregation method for message passing (e.g., “sum”).</p></li>
<li><p>mode (str): Mode for specifying tensor types (e.g., “SS” for sparse adjacency and sparse X).</p></li>
<li><p>mlp (dict): Parameters for the MLP layer.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[SparseTensor, MaskedTensor], datadict: dict) -&gt; Union[SparseTensor, MaskedTensor]:
Forward pass of the SSWLConv layer.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.Conv.SSWLConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#SSWLConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.SSWLConv.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.Conv.SUNConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.Conv.</span></span><span class="sig-name descname"><span class="pre">SUNConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#SUNConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.SUNConv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implementation of the SUNConv layer based on the paper “Understanding and extending subgraph GNNs by rethinking their symmetries” by Fabrizio Frasca et al., NeurIPS 2022.
This layer performs message passing on 2D subgraph representations with subgraph and cross-subgraph pooling.</p>
<p>Args:</p>
<ul class="simple">
<li><p>indim (int): Input feature dimension.</p></li>
<li><p>outdim (int): Output feature dimension.</p></li>
<li><p>aggr (str): Aggregation method for message passing (e.g., “sum”).</p></li>
<li><p>pool (str): Pooling method (e.g., “mean”).</p></li>
<li><p>mode (str): Mode for specifying tensor types (e.g., “SS” for sparse adjacency and sparse X).</p></li>
<li><p>mlp0 (dict): Parameters for the first MLP layer.</p></li>
<li><p>mlp1 (dict): Parameters for the second MLP layer.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[SparseTensor, MaskedTensor], datadict: dict) -&gt; Union[SparseTensor, MaskedTensor]:
Forward pass of the SUNConv layer.</p></li>
</ul>
<p>Notes:
- This layer is based on Symmetry Understanding Networks (SUN) and performs message passing on 2D subgraph representations with subgraph and cross-subgraph pooling.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.Conv.SUNConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/Conv.html#SUNConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.Conv.SUNConv.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-pygho.honn.MaOperator">
<span id="pygho-honn-maoperator-module"></span><h2>pygho.honn.MaOperator module<a class="headerlink" href="#module-pygho.honn.MaOperator" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.Op2FWL">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">Op2FWL</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#Op2FWL"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.Op2FWL" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassing" title="pygho.honn.MaOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Operator for simulating the 2-Folklore-Weisfeiler-Lehman (FWL) test. X &lt;- X1 * X2.</p>
<p>This operator is specifically designed for simulating the 2-Folklore-Weisfeiler-Lehman (FWL) test 
by performing message passing between two masked tensors ‘X1’ and ‘X2’. The result is masked as the
target masked tensor ‘tarX’.</p>
<p>Args:</p>
<ul class="simple">
<li><p>None</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>OpMessagePassing: The base class for generalized message passing.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.Op2FWL.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#Op2FWL.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.Op2FWL.forward" title="Link to this definition"></a></dt>
<dd><p>Simulate the 2-Folklore-Weisfeiler-Lehman (FWL) test by performing message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>X1 (MaskedTensor): The first input masked tensor of shape (b, n, n,*denseshapeshape1).</p></li>
<li><p>X2 (MaskedTensor): The second input masked tensor of shape (b, n, n,*denseshapeshape2).</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data.</p></li>
<li><p>tarX (MaskedTensor): The target masked tensor.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpDiag">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpDiag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpDiag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpDiag" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Operator for extracting diagonal elements from a SparseTensor.</p>
<p>Args:</p>
<ul class="simple">
<li><p>dims (Iterable[int]): A list of dimensions along which to extract diagonal elements.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpDiag.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpDiag.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpDiag.forward" title="Link to this definition"></a></dt>
<dd><p>forward function</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): The input masked Tensor</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>MaskedTensor: The diagonal elements.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpDiag2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpDiag2D</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpDiag2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpDiag2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpDiag" title="pygho.honn.MaOperator.OpDiag"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpDiag</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpDiag2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpDiag2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpDiag2D.forward" title="Link to this definition"></a></dt>
<dd><p>Extract diagonal elements from the input masked.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): The input MaskedTensor from which to extract diagonal elements. Be of shape (b, n, n,*denseshapeshape)</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>MaskedTensor: of shape (b, n,*denseshapeshape)</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[Tensor, SparseTensor]: The extracted diagonal elements as either a dense or sparse tensor.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassing" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>General message passing operator for masked tensor adjacency and masked tensor tuple representation.</p>
<p>This operator takes two input masked tensors ‘A’ and ‘B’ and performs message passing 
between them to generate a new masked tensor ‘tarX’. The resulting tensor has a shape of 
(b,* maskedshape1_dim1,* maskedshape2_dim2,*denseshapeshape), where ‘b’ represents the batch size.</p>
<p>Args:</p>
<ul class="simple">
<li><p>dim1 (int): The dimension along which message passing is applied in ‘A’.</p></li>
<li><p>dim2 (int): The dimension along which message passing is applied in ‘B’.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassing.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassing.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassing.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing between two masked tensors.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): The first input masked tensor.</p></li>
<li><p>B (MaskedTensor): The second input masked tensor.</p></li>
<li><p>tarX (MaskedTensor): The target masked tensor. The output will use its mask</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>MaskedTensor: The result of message passing, represented as a masked tensor.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>This method applies message passing between ‘A’ and ‘B’ to generate ‘tarX’.</p></li>
<li><p>It considers the specified dimensions for message passing.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassingCrossSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingCrossSubg2D</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassingCrossSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassingCrossSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassing" title="pygho.honn.MaOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Perform message passing across subgraphs within the 2D subgraph Graph Neural Network (GNN).</p>
<p>Args:</p>
<ul class="simple">
<li><p>None</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>OpMessagePassing: The base class for generalized message passing.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>It assumes that ‘A’ represents the adjacency matrix of subgraphs, and ‘X’ represents 2D representations 
of subgraph nodes.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassingCrossSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassingCrossSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassingCrossSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing across subgraphs within the 2D subgraph Graph Neural Network.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): The input masked tensor representing the adjacency matrix of subgraphs. of shape (b, n, n,*denseshapeshape1).</p></li>
<li><p>X (MaskedTensor): The input masked tensor representing 2D representations of subgraph nodes. of shape (b, n, n,*denseshapeshape2).</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data (not used in this method).</p></li>
<li><p>tarX (MaskedTensor): The target masked tensor to store the result. of  shape (b, n, n,*denseshapeshape3).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>MaskedTensor: The result of message passing that bridges subgraphs.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassingOnSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingOnSubg2D</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassingOnSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassing" title="pygho.honn.MaOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Operator for performing message passing on each subgraph for 2D subgraph Graph Neural Networks.</p>
<p>This operator is designed for use in 2D subgraph Graph Neural Networks (GNNs). It extends the 
base class <cite>OpMessagePassing</cite> to perform message passing on each subgraph represented by input tensors 
‘A’ (adjacency matrix) and ‘X’ (2D representations). The result is stored in the target masked tensor ‘tarX’.</p>
<p>Args:</p>
<ul class="simple">
<li><p>None</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>OpMessagePassing: The base class for generalized message passing.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassingOnSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassingOnSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing on each subgraph for 2D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): The input masked tensor representing the adjacency matrix of subgraphs, of shape (b, n, n,*denseshapeshape1).</p></li>
<li><p>X (MaskedTensor): The input masked tensor representing 2D representations of subgraph nodes, of shape (b, n, n,*denseshapeshape2).</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data (not used in this method).</p></li>
<li><p>tarX (MaskedTensor): The target masked tensor to mask the result.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>MaskedTensor: The result of message passing on each subgraph.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassingOnSubg3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingOnSubg3D</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassingOnSubg3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg3D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpMessagePassing" title="pygho.honn.MaOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Operator for performing message passing on each subgraph for 3D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>None</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>OpMessagePassing: The base class for generalized message passing.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpMessagePassingOnSubg3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpMessagePassingOnSubg3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpMessagePassingOnSubg3D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing on each subgraph for 3D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): The input masked tensor representing the adjacency matrix of subgraphs, of shape (b, n, n,*denseshapeshape1)</p></li>
<li><p>X (MaskedTensor): The input masked tensor representing 3D representations of subgraph nodes, of shape (b, n, n, n,*denseshapeshape2)</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data (not used in this method).</p></li>
<li><p>tarX (MaskedTensor): The target masked tensor to mask the result,  of shape (b, n, n, n,*denseshapeshape3).</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>denseshape1, denseshape2 must be broadcastable.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpNodeMessagePassing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpNodeMessagePassing</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpNodeMessagePassing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpNodeMessagePassing" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Perform node-level message passing with an adjacency matrix A of shape (b, n, n) and node features X of shape (b, n).</p>
<p>Args:</p>
<ul class="simple">
<li><p>None</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpNodeMessagePassing.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpNodeMessagePassing.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpNodeMessagePassing.forward" title="Link to this definition"></a></dt>
<dd><p>Perform forward pass of node-level message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): Adjacency matrix of shape (b, n, n).</p></li>
<li><p>X (MaskedTensor): Node features of shape (b, n).</p></li>
<li><p>tarX (MaskedTensor): Target node features of shape (b, n).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tensor: The result of the message passing operation.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPooling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpPooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPooling" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPooling.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPooling.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPoolingCrossSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpPoolingCrossSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPoolingCrossSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPoolingCrossSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpPooling" title="pygho.honn.MaOperator.OpPooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpPooling</span></code></a></p>
<p>Operator for pooling the same node representations within different subgraphsfor 2D subgraph GNNs. It returns dense output only.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>pool</cite> (str): The pooling operation to apply.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPoolingCrossSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPoolingCrossSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPoolingCrossSubg2D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (MaskedTensor): The input MaskedTensor of shape(b, n, n,*denseshapeshape) representing 2D node representations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(Tensor): The pooled dense tensor. of shape (b, n,*denseshapeshape)</p></li>
</ul>
</dd>
<dt>Raises:</dt><dd><ul class="simple">
<li><p>AssertionError: If <cite>X</cite> is not 2D representations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPoolingSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpPoolingSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPoolingSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPoolingSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpPooling" title="pygho.honn.MaOperator.OpPooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpPooling</span></code></a></p>
<p>Operator for pooling node representations within each subgraph for 2D subgraph GNNs.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>pool</cite> (str): The pooling operation to apply.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPoolingSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPoolingSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPoolingSubg2D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (MaskedTensor): The input MaskedTensor of shape(b, n, n,*denseshapeshape) representing 2D node representations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(Tensor): The pooled dense tensor. of shape (b, n,*denseshapeshape)</p></li>
</ul>
</dd>
<dt>Raises:</dt><dd><ul class="simple">
<li><p>AssertionError: If <cite>X</cite> is not 2D representations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPoolingSubg3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpPoolingSubg3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPoolingSubg3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPoolingSubg3D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpPooling" title="pygho.honn.MaOperator.OpPooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpPooling</span></code></a></p>
<p>Operator for pooling node representations within each subgraph for 3D subgraph GNNs. It returns sparse output only.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>pool</cite> (str): The pooling operation to apply.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpPoolingSubg3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpPoolingSubg3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpPoolingSubg3D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (MaskedTensor): The input MaskedTensor of shape(b, n, n, n,*denseshapeshape) representing 2D node representations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(Tensor): The pooled dense tensor. of shape (b, n, n,*denseshapeshape)</p></li>
</ul>
</dd>
<dt>Raises:</dt><dd><ul class="simple">
<li><p>AssertionError: If <cite>X</cite> is not 2D representations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpSpMessagePassing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassing" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>OpMessagePassing but use sparse adjacency matrix.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassing.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassing.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassing.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassingCrossSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpSpMessagePassingCrossSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassingCrossSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassingCrossSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassing" title="pygho.honn.MaOperator.OpSpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpSpMessagePassing</span></code></a></p>
<p>OpMessagePassingCrossSubg2D but use sparse adjacency matrix.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassingCrossSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassingCrossSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassingCrossSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassingOnSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpSpMessagePassingOnSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassingOnSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassing" title="pygho.honn.MaOperator.OpSpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpSpMessagePassing</span></code></a></p>
<p>OpMessagePassingOnSubg2D but use sparse adjacency matrix.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassingOnSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassingOnSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassingOnSubg3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpSpMessagePassingOnSubg3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassingOnSubg3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg3D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpSpMessagePassing" title="pygho.honn.MaOperator.OpSpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpSpMessagePassing</span></code></a></p>
<p>OpMessagePassingOnSubg3D but use sparse adjacency matrix.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpMessagePassingOnSubg3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpMessagePassingOnSubg3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpMessagePassingOnSubg3D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpNodeMessagePassing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpSpNodeMessagePassing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpNodeMessagePassing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpNodeMessagePassing" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Operator for node-level message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>aggr (str, optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>Attributes:</p>
<ul class="simple">
<li><p>aggr (str): The aggregation method used for message passing.</p></li>
</ul>
<p>Methods:
- forward(A: SparseTensor, X: Tensor, tarX: Tensor) -&gt; Tensor: Perform node-level message passing.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpSpNodeMessagePassing.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpSpNodeMessagePassing.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpSpNodeMessagePassing.forward" title="Link to this definition"></a></dt>
<dd><p>Perform forward pass of node-level message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): Adjacency matrix of shape (b, n, n).</p></li>
<li><p>X (MaskedTensor): Node features of shape (b, n).</p></li>
<li><p>tarX (MaskedTensor): Target node features of shape (b, n).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tensor: The result of the message passing operation.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpUnpooling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpUnpooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpUnpooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpUnpooling" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Operator for unpooling tensors by adding new dimensions.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>dims</cite> (int or Iterable[int]): The dimensions along which to unpool the tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpUnpooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpUnpooling.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpUnpooling.forward" title="Link to this definition"></a></dt>
<dd><p>Perform unpooling on tensors by adding new dimensions.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (MaskedTensor): The input tensor to unpool.</p></li>
<li><p><cite>tarX</cite> (MaskedTensor): The target MaskedTensor to mask the output.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(MaskedTensor): The result of unpooling.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpUnpoolingRootNodes2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpUnpoolingRootNodes2D</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpUnpoolingRootNodes2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpUnpoolingRootNodes2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpUnpooling" title="pygho.honn.MaOperator.OpUnpooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpUnpooling</span></code></a></p>
<p>Operator for copy root node representations to the subgraph rooted at i for all nodes</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.MaOperator.OpUnpoolingSubgNodes2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.MaOperator.</span></span><span class="sig-name descname"><span class="pre">OpUnpoolingSubgNodes2D</span></span><a class="reference internal" href="../_modules/pygho/honn/MaOperator.html#OpUnpoolingSubgNodes2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.MaOperator.OpUnpoolingSubgNodes2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.MaOperator.OpUnpooling" title="pygho.honn.MaOperator.OpUnpooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpUnpooling</span></code></a></p>
<p>Operator for copy node representations to the node representation of all subgraphs</p>
</dd></dl>

</section>
<section id="module-pygho.honn.SpOperator">
<span id="pygho-honn-spoperator-module"></span><h2>pygho.honn.SpOperator module<a class="headerlink" href="#module-pygho.honn.SpOperator" title="Link to this heading"></a></h2>
<p>Operators for SparseTensor</p>
<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.Op2FWL">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">Op2FWL</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#Op2FWL"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.Op2FWL" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassing" title="pygho.honn.SpOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Operator for simulating the 2-Folklore-Weisfeiler-Lehman (FWL) test. X &lt;- X1 * X2.</p>
<p>Args:</p>
<ul class="simple">
<li><p>aggr (str, optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(X1: SparseTensor, X2: SparseTensor, datadict: Dict, tarX: Optional[SparseTensor] = None) -&gt; SparseTensor: Simulate the 2-FWL test by performing message passing.</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>OpMessagePassing: The base class for generalized message passing.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.Op2FWL.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#Op2FWL.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.Op2FWL.forward" title="Link to this definition"></a></dt>
<dd><p>Simulate the 2-Folklore-Weisfeiler-Lehman (FWL) test by performing message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>X1 (SparseTensor): The first input sparse tensor (2D representations).</p></li>
<li><p>X2 (SparseTensor): The second input sparse tensor (2D representations).</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data.</p></li>
<li><p>tarX (Optional[SparseTensor]): The target sparse tensor (default: None).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: The result of simulating the 2-FWL test by performing message passing.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpDiag">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpDiag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_sparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpDiag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpDiag" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Operator for extracting diagonal elements from a SparseTensor.</p>
<p>Args:</p>
<ul class="simple">
<li><p>dims (Iterable[int]): A list of dimensions along which to extract diagonal elements.</p></li>
<li><p>return_sparse (bool, optional): Whether to return the diagonal elements as a SparseTensor of a Tensor (default: False).</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: SparseTensor) -&gt; Union[Tensor, SparseTensor]: Extract diagonal elements from the input SparseTensor.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>This class is used to extract diagonal elements from a SparseTensor along specified dimensions.</p></li>
<li><p>You can choose to return the diagonal elements as either a dense or sparse tensor.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpDiag.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpDiag.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpDiag.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpDiag2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpDiag2D</span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpDiag2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpDiag2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpDiag" title="pygho.honn.SpOperator.OpDiag"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpDiag</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpDiag2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpDiag2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpDiag2D.forward" title="Link to this definition"></a></dt>
<dd><p>Extract diagonal elements from the input SparseTensor.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The input SparseTensor from which to extract diagonal elements.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[Tensor, SparseTensor]: The extracted diagonal elements as either a dense or sparse tensor.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op0</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'X'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'X'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'A'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassing" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Generalized message passing on tuple features.</p>
<p>This class operates on two sparse tensors A and B and performs message passing based on specified operations and dimensions.</p>
<p>Args:</p>
<ul class="simple">
<li><p>op0 (str, optional): The operation name for the first input (default: “X”). 
It is used to compute precomputekey and retrieve precomputation results</p></li>
<li><p>op1 (str, optional): The operation name for the second input (default: “X”).</p></li>
<li><p>dim1 (int, optional): The dimension to apply op0 (default: 1).</p></li>
<li><p>op2 (str, optional): The operation name for the third input (default: “A”).</p></li>
<li><p>dim2 (int, optional): The dimension to apply op2 (default: 0).</p></li>
<li><p>aggr (str, optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>Attributes:</p>
<ul class="simple">
<li><p>dim1 (int): The dimension to apply op0.</p></li>
<li><p>dim2 (int): The dimension to apply op2.</p></li>
<li><p>precomputekey (str): The precomputed key for caching intermediate data.</p></li>
<li><p>aggr (str): The aggregation method used for message passing.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: SparseTensor, B: SparseTensor, datadict: Dict, tarX: Optional[SparseTensor] = None) -&gt; SparseTensor: Perform generalized message passing.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>This class is designed for generalized message passing on tuple features.</p></li>
<li><p>It supports specifying custom operations and dimensions for message passing.</p></li>
<li><p>The <cite>forward</cite> method performs the message passing operation and returns the result.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassing.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassing.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassing.forward" title="Link to this definition"></a></dt>
<dd><p>Perform generalized message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The first input sparse tensor.</p></li>
<li><p>B (SparseTensor): The second input sparse tensor.</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data. Containing precomputation results.</p></li>
<li><p>tarX (Optional[SparseTensor]): The target sparse tensor (default: None).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: The result of generalized message passing.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>This method performs the generalized message passing operation using the provided inputs.</p></li>
<li><p>It supports caching intermediate data in the <cite>datadict</cite> dictionary.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassingCrossSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingCrossSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassingCrossSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassingCrossSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassing" title="pygho.honn.SpOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Perform message passing across subgraphs within the 2D subgraph Graph Neural Network (GNN).</p>
<p>Args:</p>
<ul class="simple">
<li><p>aggr (str): The aggregation method in message passing</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: The result of message passing on each subgraph within the 2D subgraph GNN.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassingCrossSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassingCrossSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassingCrossSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing across subgraphs within the 2D subgraph Graph Neural Network (GNN).</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The adjacency matrix of the whole graph (nxn).</p></li>
<li><p>X (SparseTensor): The 2D representations of the subgraphs.</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data.</p></li>
<li><p>tarX (Optional[SparseTensor]): The target sparse tensor (default: None).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: The result of message passing on each subgraph within the 2D subgraph GNN.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassingOnSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingOnSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassingOnSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassing" title="pygho.honn.SpOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Operator for performing message passing on each subgraph for 2D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>aggr (str, optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: SparseTensor, X: SparseTensor, datadict: Dict, tarX: Optional[SparseTensor] = None) -&gt; SparseTensor: Perform message passing on each subgraph within the 2D subgraph GNN.</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>OpMessagePassing: The base class for generalized message passing.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassingOnSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassingOnSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing on each subgraph within the 2D subgraph Graph Neural Network (GNN).</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The adjacency matrix of the whole graph (nxn).</p></li>
<li><p>X (SparseTensor): The 2D representations of the subgraphs.</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data.</p></li>
<li><p>tarX (Optional[SparseTensor]): The target sparse tensor (default: None).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: The result of message passing on each subgraph within the 2D subgraph GNN.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassingOnSubg3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingOnSubg3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassingOnSubg3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg3D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpMessagePassing" title="pygho.honn.SpOperator.OpMessagePassing"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpMessagePassing</span></code></a></p>
<p>Operator for performing message passing on each subgraph for 3D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>aggr (str, optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: SparseTensor, X: SparseTensor, datadict: Dict, tarX: Optional[SparseTensor] = None) -&gt; SparseTensor: Perform message passing on each subgraph within the 2D subgraph GNN.</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>OpMessagePassing: The base class for generalized message passing.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpMessagePassingOnSubg3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpMessagePassingOnSubg3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpMessagePassingOnSubg3D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing on each subgraph within the 3D subgraph Graph Neural Network (GNN).</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The adjacency matrix of the whole graph (nxn).</p></li>
<li><p>X (SparseTensor): The 3D representations of the subgraphs.</p></li>
<li><p>datadict (Dict): A dictionary for caching intermediate data.</p></li>
<li><p>tarX (Optional[SparseTensor]): The target sparse tensor (default: None).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: The result of message passing on each subgraph within the 2D subgraph GNN.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpNodeMessagePassing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpNodeMessagePassing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpNodeMessagePassing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpNodeMessagePassing" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Operator for node-level message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>aggr (str, optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>Attributes:
- aggr (str): The aggregation method used for message passing.</p>
<p>Methods:
- forward(A: SparseTensor, X: Tensor, tarX: Tensor) -&gt; Tensor: Perform node-level message passing.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpNodeMessagePassing.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpNodeMessagePassing.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpNodeMessagePassing.forward" title="Link to this definition"></a></dt>
<dd><p>Perform node-level message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The adjacency matrix of the graph.</p></li>
<li><p>X (Tensor): The node feature tensor.</p></li>
<li><p>tarX (Tensor): The target node feature tensor. of no use</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tensor: The result of node-level message passing (AX).</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPooling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpPooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_sparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPooling" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Operator for pooling tuple representations by reducing dimensions.</p>
<p>Args:</p>
<ul class="simple">
<li><p>dims (Union[int, Iterable[int]]): The dimensions along which to apply pooling.</p></li>
<li><p>pool (str, optional): The pooling operation to apply (default: “sum”).</p></li>
<li><p>return_sparse (bool, optional): Whether to return the pooled tensor as a SparseTensor (default: False).</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(X: SparseTensor) -&gt; Union[SparseTensor, Tensor]: Apply pooling operation to the input SparseTensor.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPooling.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPooling.forward" title="Link to this definition"></a></dt>
<dd><p>Apply pooling operation to the input SparseTensor.</p>
<p>Args:</p>
<ul class="simple">
<li><p>X (SparseTensor): The input SparseTensor to which pooling is applied.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[SparseTensor, Tensor]: The pooled tensor as either a dense or sparse tensor.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPoolingCrossSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpPoolingCrossSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPoolingCrossSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPoolingCrossSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpPooling" title="pygho.honn.SpOperator.OpPooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpPooling</span></code></a></p>
<p>Operator for pooling the same node representations within different subgraphsfor 2D subgraph GNNs. It returns dense output only.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>pool</cite> (str): The pooling operation to apply.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPoolingCrossSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPoolingCrossSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPoolingCrossSubg2D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (SparseTensor): The input SparseTensor representing 2D node representations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(Tensor): The pooled sparse tensor.</p></li>
</ul>
</dd>
<dt>Raises:</dt><dd><ul class="simple">
<li><p>AssertionError: If <cite>X</cite> is not 2D representations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPoolingSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpPoolingSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPoolingSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPoolingSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpPooling" title="pygho.honn.SpOperator.OpPooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpPooling</span></code></a></p>
<p>Operator for pooling node representations within each subgraph for 2D subgraph GNNs. It returns dense output only.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>pool</cite> (str): The pooling operation to apply.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPoolingSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPoolingSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPoolingSubg2D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (SparseTensor): The input SparseTensor representing 2D node representations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(Tensor): The pooled dense tensor.</p></li>
</ul>
</dd>
<dt>Raises:</dt><dd><ul class="simple">
<li><p>AssertionError: If <cite>X</cite> is not 2D representations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPoolingSubg3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpPoolingSubg3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPoolingSubg3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPoolingSubg3D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpPooling" title="pygho.honn.SpOperator.OpPooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpPooling</span></code></a></p>
<p>Operator for pooling node representations within each subgraph for 3D subgraph GNNs. It returns sparse output only.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>pool</cite> (str): The pooling operation to apply.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpPoolingSubg3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpPoolingSubg3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpPoolingSubg3D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (SparseTensor): The input SparseTensor representing 2D node representations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(SparseTensor): The pooled sparse tensor.</p></li>
</ul>
</dd>
<dt>Raises:</dt><dd><ul class="simple">
<li><p>AssertionError: If <cite>X</cite> is not 3D representations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpUnpooling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpUnpooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fromdense1dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpUnpooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpUnpooling" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Operator for unpooling tensors by adding new dimensions.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>dims</cite> (int or Iterable[int]): The dimensions along which to unpool the tensor.</p></li>
<li><p><cite>fromdense1dim</cite> (bool, optional): Whether to perform unpooling from dense 1D. Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpUnpooling.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpUnpooling.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpUnpooling.forward" title="Link to this definition"></a></dt>
<dd><p>Perform unpooling on tensors by adding new dimensions.</p>
<dl class="simple">
<dt>Parameters:</dt><dd><ul class="simple">
<li><p><cite>X</cite> (Union[Tensor, SparseTensor]): The input tensor to unpool.</p></li>
<li><p><cite>tarX</cite> (SparseTensor): The target SparseTensor.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>(SparseTensor): The result of unpooling as a SparseTensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpUnpoolingRootNodes2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpUnpoolingRootNodes2D</span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpUnpoolingRootNodes2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpUnpoolingRootNodes2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpUnpooling" title="pygho.honn.SpOperator.OpUnpooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpUnpooling</span></code></a></p>
<p>Operator for copy root node representations to the subgraph rooted at i for all nodes</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.OpUnpoolingSubgNodes2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">OpUnpoolingSubgNodes2D</span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#OpUnpoolingSubgNodes2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.OpUnpoolingSubgNodes2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#pygho.honn.SpOperator.OpUnpooling" title="pygho.honn.SpOperator.OpUnpooling"><code class="xref py py-class docutils literal notranslate"><span class="pre">OpUnpooling</span></code></a></p>
<p>Operator for copy node representations to the node representation of all subgraphs</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.honn.SpOperator.parse_precomputekey">
<span class="sig-prename descclassname"><span class="pre">pygho.honn.SpOperator.</span></span><span class="sig-name descname"><span class="pre">parse_precomputekey</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pygho/honn/SpOperator.html#parse_precomputekey"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.SpOperator.parse_precomputekey" title="Link to this definition"></a></dt>
<dd><p>Parse and return precompute keys from a PyTorch model.</p>
<p>Args:</p>
<ul class="simple">
<li><p>model (Module): The PyTorch model to parse.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>List[str]: A list of unique precompute keys found in the model.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>  <span class="c1"># Initialize your PyTorch model</span>
<span class="n">precompute_keys</span> <span class="o">=</span> <span class="n">parse_precomputekey</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>Notes:
- This function is useful for extracting precompute keys from message-passing models.
- It iterates through the model’s modules and identifies instances of OpMessagePassing modules.
- The precompute keys associated with these modules are collected and returned as a list.</p>
</dd></dl>

</section>
<section id="module-pygho.honn.TensorOp">
<span id="pygho-honn-tensorop-module"></span><h2>pygho.honn.TensorOp module<a class="headerlink" href="#module-pygho.honn.TensorOp" title="Link to this heading"></a></h2>
<p>Wrappers unifying operators for sparse and masked tensors</p>
<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.Op2FWL">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">Op2FWL</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'sum'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'mean'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'max'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#Op2FWL"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.Op2FWL" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Simulate the 2-Folklore-Weisfeiler-Lehman (FWL) test with support for both sparse and masked tensors.</p>
<p>This class allows you to simulate the 2-Folklore-Weisfeiler-Lehman (FWL) test by performing message passing 
between two input tensors, X1 and X2. It supports both sparse and masked tensors and offers flexibility in
specifying the aggregation method.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“SS”, “DD”], optional): The mode indicating tensor types (default: “SS”).
SS means sparse adjacency and sparse X, DD means dense adjacency and dense X.</p></li>
<li><p>aggr (Literal[“sum”, “mean”, “max”], optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.Op2FWL: Sparse tensor operator for simulating 2-FWL.</p></li>
<li><p>MaOperator.Op2FWL: Masked tensor operator for simulating 2-FWL.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.Op2FWL.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#Op2FWL.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.Op2FWL.forward" title="Link to this definition"></a></dt>
<dd><p>Simulate the 2-Folklore-Weisfeiler-Lehman (FWL) test by performing message passing.</p>
<p>Args:</p>
<ul class="simple">
<li><p>X1 (Union[SparseTensor, MaskedTensor]): The first input tensor.</p></li>
<li><p>X2 (Union[SparseTensor, MaskedTensor]): The second input tensor.</p></li>
<li><p>datadict (Optional[Dict]): A dictionary for caching intermediate data (not used in this method).</p></li>
<li><p>tarX (Optional[Union[SparseTensor, MaskedTensor]]): The target tensor to store the result.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[SparseTensor, MaskedTensor]: The result of simulating the 2-Folklore-Weisfeiler-Lehman (FWL) test.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpDiag2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpDiag2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'D'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'S'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'S'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpDiag2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpDiag2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Perform diagonalization operation for 2D subgraph Graph Neural Networks with support for both sparse and masked tensors.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“S”, “D”], optional): The mode indicating tensor types (default: “S”).
S means sparse, D means dense</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpDiag2D: Sparse tensor operator for diagonalization in 2D GNNs.</p></li>
<li><p>MaOperator.OpDiag2D: Masked tensor operator for diagonalization in 2D GNNs.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpDiag2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpDiag2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpDiag2D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform diagonalization operation for 2D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>X (Union[MaskedTensor, SparseTensor]): The input tensor for diagonalization.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[MaskedTensor, Tensor]: The result of the diagonalization operation.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpMessagePassingCrossSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingCrossSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'sum'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'mean'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'max'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpMessagePassingCrossSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpMessagePassingCrossSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Perform message passing across subgraphs within the 2D subgraph Graph Neural Network (GNN) with support for both sparse and masked tensors.</p>
<p>This class is designed for performing message passing across subgraphs within the 2D subgraph Graph Neural Network (GNN).
It supports both sparse and masked tensors and provides flexibility in specifying the aggregation method.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“SD”, “SS”, “DD”], optional): The mode indicating tensor types (default: “SS”).</p></li>
<li><p>aggr (Literal[“sum”, “mean”, “max”], optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpMessagePassingCrossSubg2D: Sparse tensor operator for cross-subgraph message passing in 2D GNNs.</p></li>
<li><p>MaOperator.OpSpMessagePassingCrossSubg2D: Masked tensor operator for cross-subgraph message passing in 2D GNNs.</p></li>
<li><p>MaOperator.OpMessagePassingCrossSubg2D: Masked tensor operator for cross-subgraph message passing in 2D GNNs with dense adjacency.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpMessagePassingCrossSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpMessagePassingCrossSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpMessagePassingCrossSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing across subgraphs within the 2D subgraph Graph Neural Network (GNN).</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (Union[SparseTensor, MaskedTensor]): The input tensor representing the adjacency matrix of subgraphs.</p></li>
<li><p>X (Union[SparseTensor, MaskedTensor]): The input tensor representing 2D representations of subgraph nodes.</p></li>
<li><p>datadict (Optional[Dict]): A dictionary for caching intermediate data (not used in this method).</p></li>
<li><p>tarX (Optional[Union[SparseTensor, MaskedTensor]]): The target tensor to store the result.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[SparseTensor, MaskedTensor]: The result of message passing across subgraphs.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpMessagePassingOnSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingOnSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'sum'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'mean'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'max'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpMessagePassingOnSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpMessagePassingOnSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpMessagePassingOnSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing on each subgraph for 2D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (Union[SparseTensor, MaskedTensor]): The input tensor representing the adjacency matrix of subgraphs.</p></li>
<li><p>X (Union[SparseTensor, MaskedTensor]): The input tensor representing 2D representations of subgraph nodes.</p></li>
<li><p>datadict (Optional[Dict]): A dictionary for caching intermediate data (not used in this method).</p></li>
<li><p>tarX (Optional[Union[SparseTensor, MaskedTensor]]): The target tensor to store the result.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[SparseTensor, MaskedTensor]: The result of message passing on each subgraph.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpMessagePassingOnSubg3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpMessagePassingOnSubg3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'sum'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'mean'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'max'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpMessagePassingOnSubg3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg3D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Perform message passing on each subgraph for 3D subgraph Graph Neural Networks with support for both sparse and masked tensors.</p>
<p>This class is designed for performing message passing on each subgraph within 3D subgraph Graph Neural Networks.
It supports both sparse and masked tensors and provides flexibility in specifying the aggregation method.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“SD”, “SS”, “DD”], optional): The mode indicating tensor types (default: “SS”).
SS means sparse adjacency and sparse X, SD means sparse adjacency and dense X, DD means dense adjacency and dense X.</p></li>
<li><p>aggr (Literal[“sum”, “mean”, “max”], optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpMessagePassingOnSubg3D: Sparse tensor operator for message passing on 3D subgraphs.</p></li>
<li><p>MaOperator.OpSpMessagePassingOnSubg3D: Masked tensor operator for message passing on 3D subgraphs.</p></li>
<li><p>MaOperator.OpMessagePassingOnSubg3D: Masked tensor operator for message passing on 3D subgraphs with dense adjacency.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpMessagePassingOnSubg3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">datadict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpMessagePassingOnSubg3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpMessagePassingOnSubg3D.forward" title="Link to this definition"></a></dt>
<dd><p>Perform message passing on each subgraph for 3D subgraph Graph Neural Networks.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (Union[SparseTensor, MaskedTensor]): The input tensor representing the adjacency matrix of subgraphs.</p></li>
<li><p>X (Union[SparseTensor, MaskedTensor]): The input tensor representing 3D representations of subgraph nodes.</p></li>
<li><p>datadict (Optional[Dict]): A dictionary for caching intermediate data (not used in this method).</p></li>
<li><p>tarX (Optional[Union[SparseTensor, MaskedTensor]]): The target tensor to store the result.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[SparseTensor, MaskedTensor]: The result of message passing on each subgraph.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpNodeMessagePassing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpNodeMessagePassing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'SS'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'SD'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'DD'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'SS'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpNodeMessagePassing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpNodeMessagePassing" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Perform node-wise message passing with support for both sparse and masked tensors.</p>
<p>This class wraps the message passing operator, allowing it to be applied to both sparse and masked tensors.
It can perform node-wise message passing based on the provided mode and aggregation method.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“SS”, “SD”, “DD”], optional): The mode indicating tensor types (default: “SS”). 
SS means sparse adjacency and sparse X, SD means sparse adjacency and dense X, DD means dense adjacency and dense X.</p></li>
<li><p>aggr (str, optional): The aggregation method for message passing (default: “sum”).</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpNodeMessagePassing: Sparse tensor node-wise message passing operator.</p></li>
<li><p>MaOperator.OpSpNodeMessagePassing: Masked tensor node-wise message passing operator for sparse adjacency.</p></li>
<li><p>MaOperator.OpNodeMessagePassing: Masked tensor node-wise message passing operator for dense adjacency.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(A: Union[SparseTensor, MaskedTensor], X: Union[Tensor, MaskedTensor]) -&gt; Union[Tensor, MaskedTensor]:
Perform node-wise message passing on the input tensors based on the specified mode and aggregation method.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpNodeMessagePassing.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpNodeMessagePassing.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpNodeMessagePassing.forward" title="Link to this definition"></a></dt>
<dd><p>Perform node-wise message passing on the input tensors.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (Union[SparseTensor, MaskedTensor]): The input adjacency tensor.</p></li>
<li><p>X (Union[Tensor, MaskedTensor]): The input tensor representing tuple features.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Union[Tensor, MaskedTensor]: The result of node-wise message passing.</p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpPoolingCrossSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpPoolingCrossSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'S'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'D'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'S'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpPoolingCrossSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpPoolingCrossSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpPoolingCrossSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpPoolingCrossSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpPoolingCrossSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpPoolingSubg2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpPoolingSubg2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'S'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'D'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'S'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpPoolingSubg2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpPoolingSubg2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Perform pooling operation for subgraphs within 2D subgraph Graph Neural Networks by reducing dimensions.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“S”, “D”], optional): The mode indicating tensor types (default: “S”). S means sparse, D means dense</p></li>
<li><p>pool (Literal[“sum”, “mean”, “max”], optional): The pooling method (default: “sum”).</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpPoolingSubg2D: Sparse tensor operator for pooling in 2D GNNs.</p></li>
<li><p>MaOperator.OpPoolingSubg2D: Masked tensor operator for pooling in 2D GNNs.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpPoolingSubg2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpPoolingSubg2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpPoolingSubg2D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpPoolingSubg3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpPoolingSubg3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'S'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'D'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'S'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpPoolingSubg3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpPoolingSubg3D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>This class is designed for performing pooling operation across subgraphs within the 2D subgraph Graph Neural Network (GNN).</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“S”, “D”], optional): The mode indicating tensor types (default: “S”). S means sparse, D means dense.</p></li>
<li><p>pool (Literal[“sum”, “mean”, “max”], optional): The pooling method (default: “sum”).</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpPoolingCrossSubg2D: Sparse tensor operator for cross-subgraph pooling in 2D GNNs.</p></li>
<li><p>MaOperator.OpPoolingCrossSubg2D: Masked tensor operator for cross-subgraph pooling in 2D GNNs.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpPoolingSubg3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpPoolingSubg3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpPoolingSubg3D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpUnpoolingRootNodes2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpUnpoolingRootNodes2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'S'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'D'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'S'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpUnpoolingRootNodes2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpUnpoolingRootNodes2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>This class is designed for performing unpooling operation for root nodes within 2D subgraph Graph Neural Networks.
It supports both sparse and masked tensors.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“S”, “D”], optional): The mode indicating tensor types (default: “S”).</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpUnpoolingRootNodes2D: Sparse tensor operator for unpooling</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpUnpoolingRootNodes2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpUnpoolingRootNodes2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpUnpoolingRootNodes2D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpUnpoolingSubgNodes2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.TensorOp.</span></span><span class="sig-name descname"><span class="pre">OpUnpoolingSubgNodes2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'S'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'D'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'S'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpUnpoolingSubgNodes2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpUnpoolingSubgNodes2D" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>This class is designed for performing unpooling operation for subgraph nodes within 2D subgraph Graph Neural Networks.
It supports both sparse and masked tensors.</p>
<p>Args:</p>
<ul class="simple">
<li><p>mode (Literal[“S”, “D”], optional): The mode indicating tensor types (default: “S”). S means sparse, D means dense.</p></li>
</ul>
<p>See Also:</p>
<ul class="simple">
<li><p>SpOperator.OpUnpoolingSubgNodes2D: Sparse tensor operator for unpooling subgraph nodes in 2D GNNs.</p></li>
<li><p>MaOperator.OpUnpoolingSubgNodes2D: Masked tensor operator for unpooling subgraph nodes in 2D GNNs.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.TensorOp.OpUnpoolingSubgNodes2D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="backend.html#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="backend.html#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/honn/TensorOp.html#OpUnpoolingSubgNodes2D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.TensorOp.OpUnpoolingSubgNodes2D.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-pygho.honn.utils">
<span id="pygho-honn-utils-module"></span><h2>pygho.honn.utils module<a class="headerlink" href="#module-pygho.honn.utils" title="Link to this heading"></a></h2>
<p>A general MLP class</p>
<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.utils.BatchNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.utils.</span></span><span class="sig-name descname"><span class="pre">BatchNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normparam</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#BatchNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.BatchNorm" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.utils.BatchNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#BatchNorm.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.BatchNorm.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.utils.LayerNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.utils.</span></span><span class="sig-name descname"><span class="pre">LayerNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normparam</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#LayerNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.LayerNorm" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.utils.LayerNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#LayerNorm.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.LayerNorm.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.utils.MLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.utils.</span></span><span class="sig-name descname"><span class="pre">MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hiddim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numlayer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tailact</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'bn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tailbias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normparam</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#MLP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.MLP" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Multi-Layer Perceptron (MLP) module with customizable layers and activation functions.</p>
<p>Args:</p>
<ul class="simple">
<li><p>hiddim (int): Number of hidden units in each layer.</p></li>
<li><p>outdim (int): Number of output units.</p></li>
<li><p>numlayer (int): Number of hidden layers in the MLP.</p></li>
<li><p>tailact (bool): Whether to apply the activation function after the final layer.</p></li>
<li><p>dp (float): Dropout probability, if greater than 0, dropout layers are added.</p></li>
<li><p>norm (str): Normalization method to apply between layers (e.g., “bn” for BatchNorm).</p></li>
<li><p>act (str): Activation function to apply between layers (e.g., “relu”).</p></li>
<li><p>tailbias (bool): Whether to include a bias term in the final linear layer.</p></li>
<li><p>normparam (float): Parameter for normalization (e.g., momentum for BatchNorm).</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>forward(x: Tensor) -&gt; Tensor:
Forward pass of the MLP.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>This class defines a multi-layer perceptron with customizable layers, activation functions, normalization, and dropout.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.utils.MLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#MLP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.MLP.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.utils.NoneNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.utils.</span></span><span class="sig-name descname"><span class="pre">NoneNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normparam</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#NoneNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.NoneNorm" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.utils.NoneNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#NoneNorm.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.NoneNorm.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="pygho.honn.utils.NormMomentumScheduler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.honn.utils.</span></span><span class="sig-name descname"><span class="pre">NormMomentumScheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mfunc:</span> <span class="pre">~typing.Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initmomentum:</span> <span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normtype=&lt;class</span> <span class="pre">'torch.nn.modules.batchnorm.BatchNorm1d'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#NormMomentumScheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.NormMomentumScheduler" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.honn.utils.NormMomentumScheduler.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/honn/utils.html#NormMomentumScheduler.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.honn.utils.NormMomentumScheduler.step" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-pygho.honn">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pygho.honn" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hodata.html" class="btn btn-neutral float-left" title="pygho.hodata package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, GraphPKU.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>