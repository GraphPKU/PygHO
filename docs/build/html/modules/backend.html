<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pygho.backend package &mdash; PyGHO 0.0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=d45e8c67"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="pygho.hodata package" href="hodata.html" />
    <link rel="prev" title="Introduction" href="../notes/introduction.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PyGHO
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/introduction.html">Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">pygho.backend package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend.MaTensor">pygho.backend.MaTensor module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor"><code class="docutils literal notranslate"><span class="pre">MaskedTensor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.add"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.add()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.catvalue"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.catvalue()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.data"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.dense_dim"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.dense_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.denseshape"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.denseshape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.diag"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.diag()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.diagonalapply"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.diagonalapply()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.fill_masked"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.fill_masked()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.fill_masked_"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.fill_masked_()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.fullmask"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.fullmask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.mask"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.mask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.masked_dim"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.masked_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.maskedshape"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.maskedshape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.max"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.max()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.mean"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.mean()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.min"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.min()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.padvalue"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.padvalue</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.shape"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.sum"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.sum()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.to"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.to()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.tuplewiseapply"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.tuplewiseapply()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor.unpooling"><code class="docutils literal notranslate"><span class="pre">MaskedTensor.unpooling()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.MaTensor.filterinf"><code class="docutils literal notranslate"><span class="pre">filterinf()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend.Mamamm">pygho.backend.Mamamm module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Mamamm.batched_tensordot"><code class="docutils literal notranslate"><span class="pre">batched_tensordot()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Mamamm.broadcast_denseshape"><code class="docutils literal notranslate"><span class="pre">broadcast_denseshape()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Mamamm.mamamm"><code class="docutils literal notranslate"><span class="pre">mamamm()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend.SpTensor">pygho.backend.SpTensor module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor"><code class="docutils literal notranslate"><span class="pre">SparseTensor</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.add"><code class="docutils literal notranslate"><span class="pre">SparseTensor.add()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.catvalue"><code class="docutils literal notranslate"><span class="pre">SparseTensor.catvalue()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.denseshape"><code class="docutils literal notranslate"><span class="pre">SparseTensor.denseshape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.diag"><code class="docutils literal notranslate"><span class="pre">SparseTensor.diag()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.diagonalapply"><code class="docutils literal notranslate"><span class="pre">SparseTensor.diagonalapply()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.from_torch_sparse_coo"><code class="docutils literal notranslate"><span class="pre">SparseTensor.from_torch_sparse_coo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.indices"><code class="docutils literal notranslate"><span class="pre">SparseTensor.indices</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.is_coalesced"><code class="docutils literal notranslate"><span class="pre">SparseTensor.is_coalesced()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.max"><code class="docutils literal notranslate"><span class="pre">SparseTensor.max()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.mean"><code class="docutils literal notranslate"><span class="pre">SparseTensor.mean()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.nnz"><code class="docutils literal notranslate"><span class="pre">SparseTensor.nnz</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.shape"><code class="docutils literal notranslate"><span class="pre">SparseTensor.shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.sparse_dim"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sparse_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.sparseshape"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sparseshape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.sum"><code class="docutils literal notranslate"><span class="pre">SparseTensor.sum()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.to"><code class="docutils literal notranslate"><span class="pre">SparseTensor.to()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.to_torch_sparse_coo"><code class="docutils literal notranslate"><span class="pre">SparseTensor.to_torch_sparse_coo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.tuplewiseapply"><code class="docutils literal notranslate"><span class="pre">SparseTensor.tuplewiseapply()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.unpooling"><code class="docutils literal notranslate"><span class="pre">SparseTensor.unpooling()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.unpooling_fromdense1dim"><code class="docutils literal notranslate"><span class="pre">SparseTensor.unpooling_fromdense1dim()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor.values"><code class="docutils literal notranslate"><span class="pre">SparseTensor.values</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.SpTensor.coalesce"><code class="docutils literal notranslate"><span class="pre">coalesce()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.SpTensor.decodehash"><code class="docutils literal notranslate"><span class="pre">decodehash()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.SpTensor.decodehash_tight"><code class="docutils literal notranslate"><span class="pre">decodehash_tight()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.SpTensor.indicehash"><code class="docutils literal notranslate"><span class="pre">indicehash()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.SpTensor.indicehash_tight"><code class="docutils literal notranslate"><span class="pre">indicehash_tight()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend.Spmamm">pygho.backend.Spmamm module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spmamm.spmamm"><code class="docutils literal notranslate"><span class="pre">spmamm()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend.Spmm">pygho.backend.Spmm module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spmm.spmm"><code class="docutils literal notranslate"><span class="pre">spmm()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend.Spspmm">pygho.backend.Spspmm module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spspmm.filterind"><code class="docutils literal notranslate"><span class="pre">filterind()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spspmm.ptr2batch"><code class="docutils literal notranslate"><span class="pre">ptr2batch()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spspmm.spsphadamard"><code class="docutils literal notranslate"><span class="pre">spsphadamard()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spspmm.spsphadamard_ind"><code class="docutils literal notranslate"><span class="pre">spsphadamard_ind()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spspmm.spspmm"><code class="docutils literal notranslate"><span class="pre">spspmm()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spspmm.spspmm_ind"><code class="docutils literal notranslate"><span class="pre">spspmm_ind()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.Spspmm.spspmpnn"><code class="docutils literal notranslate"><span class="pre">spspmpnn()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend.utils">pygho.backend.utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pygho.backend.utils.torch_scatter_reduce"><code class="docutils literal notranslate"><span class="pre">torch_scatter_reduce()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-pygho.backend">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hodata.html">pygho.hodata package</a></li>
<li class="toctree-l1"><a class="reference internal" href="honn.html">pygho.honn package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyGHO</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">pygho.backend package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/modules/backend.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pygho-backend-package">
<h1>pygho.backend package<a class="headerlink" href="#pygho-backend-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-pygho.backend.MaTensor">
<span id="pygho-backend-matensor-module"></span><h2>pygho.backend.MaTensor module<a class="headerlink" href="#module-pygho.backend.MaTensor" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.backend.MaTensor.</span></span><span class="sig-name descname"><span class="pre">MaskedTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BoolTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padvalue</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_filled</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Represents a masked tensor with optional padding values.
This class allows you to work with tensors that have a mask indicating valid and
invalid values. You can perform various operations on the masked tensor, such as
filling masked values, computing sums, means, maximums, minimums, and more.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p>data (Tensor): The underlying data tensor of shape (*maskedshape, *denseshape)</p></li>
<li><p>mask (BoolTensor): The mask tensor of shape (*maskedshape) 
where <cite>True</cite> represents valid values, and False` represents invalid values.</p></li>
<li><p>padvalue (float, optional): The value to use for padding. Defaults to 0.</p></li>
<li><p>is_filled (bool, optional): Indicates whether the invalid values have already
been filled to the padvalue. Defaults to False.</p></li>
</ul>
<p>Attributes:</p>
<ul class="simple">
<li><p>data (Tensor): The underlying data tensor.</p></li>
<li><p>mask (BoolTensor): The mask tensor.</p></li>
<li><p>fullmask (BoolTensor): The mask tensor after broadcasting to match the data’s
dimensions.</p></li>
<li><p>padvalue (float): The padding value.</p></li>
<li><p>shape (torch.Size): The shape of the data tensor.</p></li>
<li><p>masked_dim (int): The number of dimensions in maskedshape.</p></li>
<li><p>dense_dim (int): The number of dimensions in denseshape.</p></li>
<li><p>maskedshape (torch.Size): The shape of the tensor up to the masked dimensions.</p></li>
<li><p>denseshape (torch.Size): The shape of the tensor after the masked dimensions.</p></li>
</ul>
<p>Methods:</p>
<ul class="simple">
<li><p>fill_masked_(self, val: float = 0) -&gt; None: In-place fill of masked values.</p></li>
<li><p>fill_masked(self, val: float = 0) -&gt; Tensor: Return a tensor with masked values
filled with the specified value.</p></li>
<li><p>to(self, device: torch.DeviceObjType, non_blocking: bool = True): Move the
tensor to the specified device.</p></li>
<li><p>sum(self, dims: Union[Iterable[int], int], keepdim: bool = False): Compute the
sum of masked values along specified dimensions.</p></li>
<li><p>mean(self, dims: Union[Iterable[int], int], keepdim: bool = False): Compute
the mean of masked values along specified dimensions.</p></li>
<li><p>max(self, dims: Union[Iterable[int], int], keepdim: bool = False): Compute the
maximum of masked values along specified dimensions.</p></li>
<li><p>min(self, dims: Union[Iterable[int], int], keepdim: bool = False): Compute the
minimum of masked values along specified dimensions.</p></li>
<li><p>diag(self, dims: Iterable[int]): Extract diagonals from the tensor. 
The dimensions in dims will be take diagonal and put at dims[0]</p></li>
<li><p>unpooling(self, dims: Union[int, Iterable[int]], tarX): Perform unpooling
operation along specified dimensions.</p></li>
<li><p>tuplewiseapply(self, func: Callable[[Tensor], Tensor]): Apply a function to
each element of the masked tensor.</p></li>
<li><p>diagonalapply(self, func: Callable[[Tensor, LongTensor], Tensor]): Apply a
function to diagonal elements of the masked tensor.</p></li>
<li><p>add(self, tarX, samesparse: bool): Add two masked tensors together.</p></li>
<li><p>catvalue(self, tarX, samesparse: bool): Concatenate values of two masked
tensors.</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tarX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samesparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.add" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.catvalue">
<span class="sig-name descname"><span class="pre">catvalue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tarX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samesparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.catvalue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.catvalue" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.data">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">data</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.data" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.dense_dim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dense_dim</span></span><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.dense_dim" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.denseshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">denseshape</span></span><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.denseshape" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.diag">
<span class="sig-name descname"><span class="pre">diag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.diag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.diag" title="Link to this definition"></a></dt>
<dd><p>put the reduced output to dim[0]</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.diagonalapply">
<span class="sig-name descname"><span class="pre">diagonalapply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LongTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.diagonalapply"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.diagonalapply" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.fill_masked">
<span class="sig-name descname"><span class="pre">fill_masked</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.fill_masked"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.fill_masked" title="Link to this definition"></a></dt>
<dd><p>return a tensor with masked values filled with val.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.fill_masked_">
<span class="sig-name descname"><span class="pre">fill_masked_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.fill_masked_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.fill_masked_" title="Link to this definition"></a></dt>
<dd><p>inplace fill the masked values</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.fullmask">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fullmask</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">BoolTensor</span></em><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.fullmask" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.mask">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mask</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">BoolTensor</span></em><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.mask" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.masked_dim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">masked_dim</span></span><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.masked_dim" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.maskedshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">maskedshape</span></span><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.maskedshape" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.max">
<span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.max"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.max" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.mean" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.min">
<span class="sig-name descname"><span class="pre">min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.min"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.min" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.padvalue">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">padvalue</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.padvalue" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.shape" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.sum">
<span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.sum" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeviceObjType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.to" title="Link to this definition"></a></dt>
<dd><p>move data to some device</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.tuplewiseapply">
<span class="sig-name descname"><span class="pre">tuplewiseapply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.tuplewiseapply"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.tuplewiseapply" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.MaskedTensor.unpooling">
<span class="sig-name descname"><span class="pre">unpooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#MaskedTensor.unpooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.MaskedTensor.unpooling" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.MaTensor.filterinf">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.MaTensor.</span></span><span class="sig-name descname"><span class="pre">filterinf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filled_value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/MaTensor.html#filterinf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.MaTensor.filterinf" title="Link to this definition"></a></dt>
<dd><p>Replaces positive and negative infinity values in a tensor with a specified value.</p>
<p>Args:</p>
<ul class="simple">
<li><p>X (Tensor): The input tensor.</p></li>
<li><p>filled_value (float, optional): The value to replace positive and negative
infinity values with (default: 0).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tensor: A tensor with positive and negative infinity values replaced by the
specified <cite>filled_value</cite>.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">filterinf</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">filled_value</span><span class="o">=</span><span class="mf">999.0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-pygho.backend.Mamamm">
<span id="pygho-backend-mamamm-module"></span><h2>pygho.backend.Mamamm module<a class="headerlink" href="#module-pygho.backend.Mamamm" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Mamamm.batched_tensordot">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Mamamm.</span></span><span class="sig-name descname"><span class="pre">batched_tensordot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">catdim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">catdim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/Mamamm.html#batched_tensordot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Mamamm.batched_tensordot" title="Link to this definition"></a></dt>
<dd><p>Perform a batched tensordot matrix operation.</p>
<p>This function computes the tensordot product of two tensors <cite>A</cite> and <cite>B</cite>, where <cite>A</cite> and <cite>B</cite> are batched tensors with specified concatenation dimensions <cite>catdim1</cite> and <cite>catdim2</cite>, and contraction dimensions <cite>dim1</cite> and <cite>dim2</cite>.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (Tensor): The first batched tensor of shape (catshape1, broadcastshape).</p></li>
<li><p>catdim1 (int): The length of catshape1.</p></li>
<li><p>dim1 (int): The contraction dimension along <cite>catdim1</cite> of the first tensor.</p></li>
<li><p>B (Tensor): The second batched tensor of shape (catshape2, broadcastshape)..</p></li>
<li><p>catdim2 (int): The length of catshape2.</p></li>
<li><p>dim2 (int): The contraction dimension along <cite>catdim2</cite> of the second tensor.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tensor: The result of the batched tensordot operation of shape (*catshape1dim1, *catshape2dim2, *broadcastshape), where densedim is the common dense dimension of <cite>A</cite> and <cite>B</cite>.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p><cite>catdim1</cite> and <cite>catdim2</cite> specify the number of concatenation dimensions of <cite>A</cite> and <cite>B</cite>, respectively.</p></li>
<li><p><cite>dim1</cite> and <cite>dim2</cite> specify the contraction dimensions along <cite>catdim1</cite> and <cite>catdim2</cite>, respectively.</p></li>
<li><p>The function uses optimized paths for specific cases (e.g., when <cite>catdim1=2</cite> and <cite>catdim2=2</cite>).</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Mamamm.broadcast_denseshape">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Mamamm.</span></span><span class="sig-name descname"><span class="pre">broadcast_denseshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">densedim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">densedim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pygho/backend/Mamamm.html#broadcast_denseshape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Mamamm.broadcast_denseshape" title="Link to this definition"></a></dt>
<dd><p>This function broadcasts the dense shapes of tensors <cite>A</cite> and <cite>B</cite> to the same by adding dimensions of size 1.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (Tensor): The first tensor.</p></li>
<li><p>densedim1 (int): The number of dense dimension of the first tensor.</p></li>
<li><p>B (Tensor): The second tensor.</p></li>
<li><p>densedim2 (int): The number of dense dimension of the second tensor.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tuple[Tensor, Tensor]: A tuple containing the broadcasted tensors <cite>A</cite> and <cite>B</cite> with compatible dense shapes.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>This function adds dimensions with size 1 to the smaller dense shape until both dense shapes match.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Mamamm.mamamm">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Mamamm.</span></span><span class="sig-name descname"><span class="pre">mamamm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BoolTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">broadcast_firstdim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/backend/Mamamm.html#mamamm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Mamamm.mamamm" title="Link to this definition"></a></dt>
<dd><p>Batched masked matrix multiplication of two MaskedTensors.</p>
<p>This function performs batched matrix multiplication between two MaskedTensors <cite>A</cite> and <cite>B</cite>, where the masked dimensions <cite>dim1</cite> and <cite>dim2</cite> are contracted. The result is a new MaskedTensor with the specified mask.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (MaskedTensor): The first MaskedTensor with shape (B,* maskedshape1,*denseshapeshape).</p></li>
<li><p>dim1 (int): The masked dimension to contract in the first tensor <cite>A</cite>.</p></li>
<li><p>B (MaskedTensor): The second MaskedTensor with shape (B,* maskedshape2,*denseshapeshape).</p></li>
<li><p>dim2 (int): The masked dimension to contract in the second tensor <cite>B</cite>.</p></li>
<li><p>mask (BoolTensor): The mask to apply to the resulting MaskedTensor.</p></li>
<li><p>broadcast_firstdim (bool, optional): If True, broadcast the first dimension (batch dimension) of <cite>A</cite> and <cite>B</cite> to ensure compatibility. Default is True.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>MaskedTensor: A new MaskedTensor with shape (B,* maskedshape1dim1,* maskedshape2dim2,*denseshapeshape) and the specified mask.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>This function performs batched matrix multiplication between two MaskedTensors, contracting the specified masked dimensions.</p></li>
</ul>
</dd></dl>

</section>
<section id="module-pygho.backend.SpTensor">
<span id="pygho-backend-sptensor-module"></span><h2>pygho.backend.SpTensor module<a class="headerlink" href="#module-pygho.backend.SpTensor" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pygho.backend.SpTensor.</span></span><span class="sig-name descname"><span class="pre">SparseTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_coalesced</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Represents a sparse tensor in coo format.</p>
<p>This class allows you to work with sparse tensors represented by indices and
values. It provides various operations such as sum, max, mean, unpooling,
diagonal extraction, and more.</p>
<p>Parameters:
- indices (LongTensor): The indices of the sparse tensor, of shape (#sparsedim, #nnz).
- values (Optional[Tensor]): The values associated with the indices, of shape (#nnz,*denseshapeshape). Should have the same number of nnz as indices. Defaults to None.
- shape (Optional[List[int]]): The shape of the sparse tensor. If None, it is computed from the indices and values. Defaults to None.
- is_coalesced (bool): Indicates whether the indices and values are coalesced. Defaults to False.</p>
<p>Methods:
- is_coalesced(self): Check if the tensor is coalesced.
- to(self, device: torch.DeviceObjType, non_blocking: bool = False): Move the tensor to the specified device.
- diag(self, dims: Optional[Iterable[int]], return_sparse: bool = False): Extract diagonal elements from the tensor. The dimensions in dims will be take diagonal and put at dims[0]
- sum(self, dims: Union[int, Optional[Iterable[int]]], return_sparse: bool = False): Compute the sum of tensor values along specified dimensions. return_sparse=True will return a sparse tensor, otherwise return a dense tensor.
- max(self, dims: Union[int, Optional[Iterable[int]]], return_sparse: bool = False): Compute the maximum of tensor values along specified dimensions. return_sparse=True will return a sparse tensor, otherwise return a dense tensor.
- mean(self, dims: Union[int, Optional[Iterable[int]]], return_sparse: bool = False): Compute the mean of tensor values along specified dimensions. return_sparse=True will return a sparse tensor, otherwise return a dense tensor.
- unpooling(self, dims: Union[int, Iterable[int]], tarX): Perform unpooling operation along specified dimensions.
- tuplewiseapply(self, func: Callable[[Tensor], Tensor]): Apply a function to each element of the tensor.
- diagonalapply(self, func: Callable[[Tensor, LongTensor], Tensor]): Apply a function to diagonal elements of the tensor.
- add(self, tarX, samesparse: bool): Add two sparse tensors together. samesparse=True means that two sparse tensor have the indice and can add values directly. 
- catvalue(self, tarX, samesparse: bool): Concatenate values of two sparse tensors. samesparse=True means that two sparse tensor have the indice and can cat values along the first dimension directly. 
- from_torch_sparse_coo(cls, A: torch.Tensor): Create a SparseTensor from a torch sparse COO tensor.
- to_torch_sparse_coo(self) -&gt; Tensor: Convert the SparseTensor to a torch sparse COO tensor.</p>
<p>Attributes:
- indices (LongTensor): The indices of the sparse tensor.
- values (Tensor): The values associated with the indices.
- sparse_dim (int): The number of dimensions represented by the indices.
- nnz (int): The number of non-zero values.
- shape (torch.Size): The shape of the tensor.
- sparseshape (torch.Size): The shape of the tensor up to the sparse dimensions.
- denseshape (torch.Size): The shape of the tensor after the sparse dimensions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tarX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samesparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.add" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.catvalue">
<span class="sig-name descname"><span class="pre">catvalue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tarX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samesparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.catvalue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.catvalue" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.denseshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">denseshape</span></span><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.denseshape" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.diag">
<span class="sig-name descname"><span class="pre">diag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_sparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.diag"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.diag" title="Link to this definition"></a></dt>
<dd><p>TODO: unit test ??</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.diagonalapply">
<span class="sig-name descname"><span class="pre">diagonalapply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LongTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.diagonalapply"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.diagonalapply" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.from_torch_sparse_coo">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_torch_sparse_coo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.from_torch_sparse_coo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.from_torch_sparse_coo" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.indices">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">indices</span></span><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.indices" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.is_coalesced">
<span class="sig-name descname"><span class="pre">is_coalesced</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.is_coalesced"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.is_coalesced" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.max">
<span class="sig-name descname"><span class="pre">max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_sparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.max"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.max" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_sparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.mean" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.nnz">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">nnz</span></span><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.nnz" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.shape" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.sparse_dim">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sparse_dim</span></span><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.sparse_dim" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.sparseshape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sparseshape</span></span><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.sparseshape" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.sum">
<span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_sparse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.sum" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeviceObjType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.to" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.to_torch_sparse_coo">
<span class="sig-name descname"><span class="pre">to_torch_sparse_coo</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.to_torch_sparse_coo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.to_torch_sparse_coo" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.tuplewiseapply">
<span class="sig-name descname"><span class="pre">tuplewiseapply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.tuplewiseapply"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.tuplewiseapply" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.unpooling">
<span class="sig-name descname"><span class="pre">unpooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tarX</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.unpooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.unpooling" title="Link to this definition"></a></dt>
<dd><p>unpooling to of tarX indice
dims: of tarX</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.unpooling_fromdense1dim">
<span class="sig-name descname"><span class="pre">unpooling_fromdense1dim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#SparseTensor.unpooling_fromdense1dim"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.unpooling_fromdense1dim" title="Link to this definition"></a></dt>
<dd><p>unpooling to of self shape. Note the dims is for self to maintain, and expand other dims</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.SparseTensor.values">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">values</span></span><a class="headerlink" href="#pygho.backend.SpTensor.SparseTensor.values" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.coalesce">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.SpTensor.</span></span><span class="sig-name descname"><span class="pre">coalesce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">edge_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_attr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#coalesce"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.coalesce" title="Link to this definition"></a></dt>
<dd><p>Coalesces and reduces duplicate entries in edge indices and attributes.</p>
<p>Args:</p>
<ul class="simple">
<li><p>edge_index (LongTensor): The edge indices.</p></li>
<li><p>edge_attr (Tensor or List[Tensor], optional): Edge weights or multi-dimensional
edge features. If given as a list, it will be reshuffled and duplicates will be
removed for all entries. (default: None)</p></li>
<li><p>reduce (str, optional): The reduction operation to use for merging edge features.
Options include ‘sum’, ‘mean’, ‘min’, ‘max’, ‘mul’. (default: ‘sum’)</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tuple[Tensor, Optional[Tensor]]: A tuple containing the coalesced edge indices
and the coalesced and reduced edge attributes (if provided). If edge_attr is
None, the second element will be None.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.decodehash">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.SpTensor.</span></span><span class="sig-name descname"><span class="pre">decodehash</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indhash</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LongTensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#decodehash"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.decodehash" title="Link to this definition"></a></dt>
<dd><p>Decodes a hashed LongTensor into tuples of indices.</p>
<p>This function takes a hashed LongTensor and decodes it into pairs of indices,
which is commonly used in sparse tensor operations.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p>indhash (LongTensor): The input hashed LongTensor of shape (nnz).</p></li>
<li><p>sparse_dim (int): The number of dimensions represented by the hash.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>LongTensor: A LongTensor representing pairs of indices.</p></li>
</ul>
<p>Raises:</p>
<ul class="simple">
<li><p>AssertionError: If the input tensor doesn’t have the expected shape or
if the sparse dimension is invalid.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">hashed</span> <span class="o">=</span> <span class="n">indicehash</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">decodehash</span><span class="p">(</span><span class="n">hashed</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.decodehash_tight">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.SpTensor.</span></span><span class="sig-name descname"><span class="pre">decodehash_tight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indhash</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimsize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LongTensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#decodehash_tight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.decodehash_tight" title="Link to this definition"></a></dt>
<dd><p>Decodes a tightly hashed LongTensor into pairs of indices considering dimension sizes.</p>
<p>Parameters:
- indhash (LongTensor): The input hashed LongTensor of shape (nnz).
- dimsize (LongTensor): The sizes of each dimension in the sparse tensor of shape (sparse_dim).</p>
<p>Returns:
- LongTensor: A LongTensor representing pairs of indices.</p>
<p>Raises:
- AssertionError: If the input tensors don’t have the expected shapes or if the total size exceeds the range that torch.long can express.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">dim_sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">hashed</span> <span class="o">=</span> <span class="n">indicehash_tight</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dim_sizes</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">decodehash_tight</span><span class="p">(</span><span class="n">hashed</span><span class="p">,</span> <span class="n">dim_sizes</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.indicehash">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.SpTensor.</span></span><span class="sig-name descname"><span class="pre">indicehash</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indice</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LongTensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#indicehash"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.indicehash" title="Link to this definition"></a></dt>
<dd><p>Hashes a indice of shape (sparse_dim, nnz) to a single LongTensor of shape (nnz). Keep lexicographic order.</p>
<p>Parameters:
- indice (LongTensor): The input indices tensor of shape (sparse_dim, nnz).</p>
<p>Returns:
- LongTensor: A single LongTensor representing the hashed values.</p>
<p>Raises:
- AssertionError: If the input tensor doesn’t have the expected shape or if the indices are too large or if there exists negative indice.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">hashed</span> <span class="o">=</span> <span class="n">indicehash</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.SpTensor.indicehash_tight">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.SpTensor.</span></span><span class="sig-name descname"><span class="pre">indicehash_tight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indice</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dimsize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LongTensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/SpTensor.html#indicehash_tight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.SpTensor.indicehash_tight" title="Link to this definition"></a></dt>
<dd><p>Hashes a 2D LongTensor of indices tightly into a single LongTensor.
Equivalently, it compute the indice of flattened sparse tensor with indice and dimsize</p>
<p>Parameters:
- indice (LongTensor): The input indices tensor of shape (sparse_dim, nnz).
- dimsize (LongTensor): The sizes of each dimension in the sparse tensor of shape (sparse_dim).</p>
<p>Returns:
- LongTensor: A single LongTensor representing the tightly hashed values.</p>
<p>Raises:
- AssertionError: If the input tensors don’t have the expected shapes or if the indices exceed the dimension sizes.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">dim_sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">hashed</span> <span class="o">=</span> <span class="n">indicehash_tight</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dim_sizes</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-pygho.backend.Spmamm">
<span id="pygho-backend-spmamm-module"></span><h2>pygho.backend.Spmamm module<a class="headerlink" href="#module-pygho.backend.Spmamm" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spmamm.spmamm">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spmamm.</span></span><span class="sig-name descname"><span class="pre">spmamm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BoolTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pygho.backend.MaTensor.MaskedTensor" title="pygho.backend.MaTensor.MaskedTensor"><span class="pre">MaskedTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/backend/Spmamm.html#spmamm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spmamm.spmamm" title="Link to this definition"></a></dt>
<dd><p>SparseTensor-MaskedTensor multiplication.</p>
<p>This function performs multiplication between a SparseTensor <cite>A</cite> and a MaskedTensor <cite>B</cite>. The specified dimensions <cite>dim1</cite> and <cite>dim2</cite> are contracted during the multiplication, and the result is returned as a MaskedTensor.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The SparseTensor with shape (B, n, m, *shape).</p></li>
<li><p>dim1 (int): The dimension to contract in the SparseTensor <cite>A</cite>.</p></li>
<li><p>B (MaskedTensor): The MaskedTensor with shape (B, m, *shape).</p></li>
<li><p>dim2 (int): The dimension to contract in the MaskedTensor <cite>B</cite>.</p></li>
<li><p>mask (BoolTensor, optional): The mask to apply to the resulting MaskedTensor. Default is None.</p></li>
<li><p>aggr (str, optional): The aggregation method for reduction during multiplication (e.g., “sum”, “max”). Default is “sum”.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>MaskedTensor: A new MaskedTensor with shape (B, n,*denseshapeshape) and the specified mask.</p></li>
</ul>
<p>Notes:
- This function performs multiplication between a SparseTensor and a MaskedTensor, contracting the specified dimensions.
- The <cite>aggr</cite> parameter controls the reduction operation during multiplication.
- The result is returned as a MaskedTensor.</p>
</dd></dl>

</section>
<section id="module-pygho.backend.Spmm">
<span id="pygho-backend-spmm-module"></span><h2>pygho.backend.Spmm module<a class="headerlink" href="#module-pygho.backend.Spmm" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spmm.spmm">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spmm.</span></span><span class="sig-name descname"><span class="pre">spmm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/Spmm.html#spmm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spmm.spmm" title="Link to this definition"></a></dt>
<dd><p>SparseTensor, Tensor matrix multiplication.</p>
<p>This function performs a matrix multiplication between a SparseTensor <cite>A</cite> and a dense tensor <cite>X</cite> along the specified dimension <cite>dim1</cite>. The result is a dense tensor. The <cite>aggr</cite> parameter specifies the reduction operation used for merging the resulting values.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The SparseTensor used for multiplication.</p></li>
<li><p>dim1 (int): The dimension along which <cite>A</cite> is reduced.</p></li>
<li><p>X (Tensor): The dense tensor to be multiplied with <cite>A</cite>. It dim 0 will be reduced.</p></li>
<li><p>aggr (str, optional): The reduction operation to use for merging edge features (“sum”, “min”, “max”, “mean”). Defaults to “sum”.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tensor: A dense tensor containing the result of the matrix multiplication.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p><cite>A</cite> should be a 2-dimensional SparseTensor.</p></li>
<li><p>The dense shapes of <cite>A</cite> and <cite>X</cite> other than <cite>dim1</cite> must be broadcastable.</p></li>
</ul>
</dd></dl>

</section>
<section id="module-pygho.backend.Spspmm">
<span id="pygho-backend-spspmm-module"></span><h2>pygho.backend.Spspmm module<a class="headerlink" href="#module-pygho.backend.Spspmm" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spspmm.filterind">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spspmm.</span></span><span class="sig-name descname"><span class="pre">filterind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tar_ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bcd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LongTensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/Spspmm.html#filterind"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spspmm.filterind" title="Link to this definition"></a></dt>
<dd><p>A combination of Hadamard and Sparse Matrix Multiplication.</p>
<p>Given the indices <cite>tar_ind</cite> of sparse tensor A, the indices <cite>ind</cite> of sparse tensor BC, and the index array <cite>bcd</cite>, this function returns an index array <cite>acd</cite>, where <cite>(A ⊙ (BC)).val[a] = A.val[a] * scatter(B.val[c] * C.val[d], a)</cite>.</p>
<p>Args:</p>
<ul class="simple">
<li><p>tar_ind (LongTensor): The indices of sparse tensor A.</p></li>
<li><p>ind (LongTensor): The indices of sparse tensor BC.</p></li>
<li><p>bcd (LongTensor): An index array representing <cite>(BC).val</cite>.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>LongTensor: An index array <cite>acd</cite> representing the filtered indices.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tar_ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">bcd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">acd</span> <span class="o">=</span> <span class="n">filterind</span><span class="p">(</span><span class="n">tar_ind</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">bcd</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spspmm.ptr2batch">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spspmm.</span></span><span class="sig-name descname"><span class="pre">ptr2batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ptr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LongTensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/Spspmm.html#ptr2batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spspmm.ptr2batch" title="Link to this definition"></a></dt>
<dd><p>Converts a pointer tensor to a batch tensor. TODO: use torch_scatter gather instead?</p>
<p>This function takes a pointer tensor <cite>ptr</cite> and a <cite>dim_size</cite> and converts it to a
batch tensor where each element in the batch tensor corresponds to a range of
indices in the original tensor.</p>
<p>Args:</p>
<ul class="simple">
<li><p>ptr (LongTensor): The pointer tensor, where <cite>ptr[0] = 0</cite> and <cite>torch.all(diff(ptr) &gt;= 0)</cite> is true.</p></li>
<li><p>dim_size (int): The size of the target dimension.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>LongTensor: A batch tensor of shape <cite>(dim_size,)</cite> where <cite>batch[ptr[i]:ptr[i+1]] = i</cite>.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spspmm.spsphadamard">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spspmm.</span></span><span class="sig-name descname"><span class="pre">spsphadamard</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">b2a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/backend/Spspmm.html#spsphadamard"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spspmm.spsphadamard" title="Link to this definition"></a></dt>
<dd><p>Element-wise Hadamard product between two SparseTensors.</p>
<p>This function performs the element-wise Hadamard product between two SparseTensors, <cite>A</cite> and <cite>B</cite>. The <cite>b2a</cite> parameter is an optional auxiliary index produced by the <cite>spsphadamard_ind</cite> function.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The first SparseTensor.</p></li>
<li><p>B (SparseTensor): The second SparseTensor.</p></li>
<li><p>b2a (LongTensor, optional): An optional index array produced by <cite>spsphadamard_ind</cite>. If not provided, it will be computed.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: A SparseTensor containing the result of the Hadamard product.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>Both <cite>A</cite> and <cite>B</cite> must be coalesced SparseTensors.</p></li>
<li><p>The dense shapes of <cite>A</cite> and <cite>B</cite> must be broadcastable.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spspmm.spsphadamard_ind">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spspmm.</span></span><span class="sig-name descname"><span class="pre">spsphadamard_ind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tar_ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LongTensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/Spspmm.html#spsphadamard_ind"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spspmm.spsphadamard_ind" title="Link to this definition"></a></dt>
<dd><p>Auxiliary function for SparseTensor-SparseTensor Hadamard product.</p>
<p>This function is an auxiliary function used in the Hadamard product of two sparse tensors. Given the indices <cite>tar_ind</cite> of sparse tensor A and the indices <cite>ind</cite> of sparse tensor B, this function returns an index array <cite>b2a</cite> of shape <cite>(ind.shape[1],)</cite> such that <cite>ind[:, i]</cite> matches <cite>tar_ind[:, b2a[i]]</cite> for each <cite>i</cite>. If <cite>b2a[i]</cite> is less than 0, it means <cite>ind[:, i]</cite> is not matched.</p>
<p>Args:</p>
<ul class="simple">
<li><p>tar_ind (LongTensor): The indices of sparse tensor A.</p></li>
<li><p>ind (LongTensor): The indices of sparse tensor B.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>LongTensor: An index array <cite>b2a</cite> representing the matching indices between <cite>tar_ind</cite> and <cite>ind</cite>.
b2a of shape ind.shape[1]. ind[:, i] matches tar_ind[:, b2a[i]]. if b2a[i]&lt;0, ind[:, i] is not matched</p></li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tar_ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">ind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">b2a</span> <span class="o">=</span> <span class="n">spsphadamard_ind</span><span class="p">(</span><span class="n">tar_ind</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spspmm.spspmm">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spspmm.</span></span><span class="sig-name descname"><span class="pre">spspmm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bcd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tar_ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/backend/Spspmm.html#spspmm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spspmm.spspmm" title="Link to this definition"></a></dt>
<dd><p>SparseTensor SparseTensor matrix multiplication at a specified sparse dimension.</p>
<p>This function performs matrix multiplication between two SparseTensors, <cite>A</cite> and <cite>B</cite>, at the specified sparse dimensions <cite>dim1</cite> and <cite>dim2</cite>. The result is a SparseTensor containing the result of the multiplication. The <cite>aggr</cite> parameter specifies the reduction operation used for merging the resulting values.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The first SparseTensor.</p></li>
<li><p>dim1 (int): The dimension along which <cite>A</cite> is multiplied.</p></li>
<li><p>B (SparseTensor): The second SparseTensor.</p></li>
<li><p>dim2 (int): The dimension along which <cite>B</cite> is multiplied.</p></li>
<li><p>aggr (str, optional): The reduction operation to use for merging edge features (“sum”, “min”, “max”, “mean”). Defaults to “sum”.</p></li>
<li><p>bcd (LongTensor, optional): An optional auxiliary index array produced by spspmm_ind.</p></li>
<li><p>tar_ind (LongTensor, optional): An optional target index array for the output. If not provided, it will be computed.</p></li>
<li><p>acd (LongTensor, optional): An optional auxiliary index array produced by filterind.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: A SparseTensor containing the result of the matrix multiplication.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>Both <cite>A</cite> and <cite>B</cite> must be coalesced SparseTensors.</p></li>
<li><p>The dense shapes of <cite>A</cite> and <cite>B</cite> must be broadcastable.</p></li>
<li><p>This function allows for optional indices <cite>bcd</cite> and <cite>tar_ind</cite> for improved performance and control.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spspmm.spspmm_ind">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spspmm.</span></span><span class="sig-name descname"><span class="pre">spspmm_ind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ind1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ind2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_k2_sorted</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">LongTensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LongTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/pygho/backend/Spspmm.html#spspmm_ind"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spspmm.spspmm_ind" title="Link to this definition"></a></dt>
<dd><p>Sparse-sparse matrix multiplication for indices.</p>
<p>This function performs a sparse-sparse matrix multiplication for indices. 
Given two sets of indices <cite>ind1</cite> and <cite>ind2</cite>, this function eliminates <cite>dim1</cite> in <cite>ind1</cite> and <cite>dim2</cite> in <cite>ind2</cite>, and concatenates the remaining dimensions.</p>
<p>The result represents the product of the input indices.</p>
<p>Args:</p>
<ul class="simple">
<li><p>ind1 (LongTensor): The indices of the first sparse tensor of shape <cite>(sparsedim1, M1)</cite>.</p></li>
<li><p>dim1 (int): The dimension to eliminate in <cite>ind1</cite>.</p></li>
<li><p>ind2 (LongTensor): The indices of the second sparse tensor of shape <cite>(sparsedim2, M2)</cite>.</p></li>
<li><p>dim2 (int): The dimension to eliminate in <cite>ind2</cite>.</p></li>
<li><p>is_k2_sorted (bool, optional): Whether <cite>ind2</cite> is sorted along <cite>dim2</cite>. Defaults to <cite>False</cite>.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>tarind: LongTensor: The resulting indices after performing the sparse-sparse matrix    multiplication.</p></li>
<li><p>bcd: LongTensor: In tensor perspective (*i_1, k, *i_2), (*j_1, k, *j_2) -&gt; (*i_1, *i_2, *j_1, *j_2).
The return indice is of shape (3, nnz), (b, c, d), c represent index of *i, d represent index of *j, b represent index of output.For i=1,2,…,nnz,  val1[c[i]] * val2[d[i]] will be add to output val’s b[i]-th element.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ind1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">dim1</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ind2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">dim2</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">spspmm_ind</span><span class="p">(</span><span class="n">ind1</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">ind2</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.Spspmm.spspmpnn">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.Spspmm.</span></span><span class="sig-name descname"><span class="pre">spspmpnn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">B</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">acd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">message_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LongTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sum'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#pygho.backend.SpTensor.SparseTensor" title="pygho.backend.SpTensor.SparseTensor"><span class="pre">SparseTensor</span></a></span></span><a class="reference internal" href="../_modules/pygho/backend/Spspmm.html#spspmpnn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.Spspmm.spspmpnn" title="Link to this definition"></a></dt>
<dd><p>SparseTensor SparseTensor matrix multiplication at a specified sparse dimension using a message function.</p>
<p>This function extend matrix multiplication between two SparseTensors, <cite>A</cite> and <cite>B</cite>, at the specified sparse dimensions <cite>dim1</cite> and <cite>dim2</cite>, while using a message function <cite>message_func</cite> to compute the messages sent from <cite>A</cite> to <cite>B</cite> and <cite>C</cite>. The result is a SparseTensor containing the result of the multiplication. The <cite>aggr</cite> parameter specifies the reduction operation used for merging the resulting values.</p>
<p>Args:</p>
<ul class="simple">
<li><p>A (SparseTensor): The first SparseTensor.</p></li>
<li><p>dim1 (int): The dimension along which <cite>A</cite> is multiplied.</p></li>
<li><p>B (SparseTensor): The second SparseTensor.</p></li>
<li><p>dim2 (int): The dimension along which <cite>B</cite> is multiplied.</p></li>
<li><p>C (SparseTensor): The third SparseTensor.</p></li>
<li><p>acd (LongTensor): The auxiliary index array produced by a previous operation.</p></li>
<li><p>message_func (Callable): A callable function that computes the messages between <cite>A</cite>, <cite>B</cite>, and <cite>C</cite>.</p></li>
<li><p>aggr (str, optional): The reduction operation to use for merging edge features (“sum”, “min”, “max”, “mul”, “any”). Defaults to “sum”.</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>SparseTensor: A SparseTensor containing the result of the matrix multiplication.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>Both <cite>A</cite> and <cite>B</cite> must be coalesced SparseTensors.</p></li>
<li><p>The dense shapes of <cite>A</cite>, <cite>B</cite>, and <cite>C</cite> must be broadcastable.</p></li>
<li><p>The <cite>message_func</cite> should take four arguments: <cite>A_values</cite>, <cite>B_values</cite>, <cite>C_values</cite>, and <cite>acd</cite>, and return messages based on custom logic.</p></li>
</ul>
</dd></dl>

</section>
<section id="module-pygho.backend.utils">
<span id="pygho-backend-utils-module"></span><h2>pygho.backend.utils module<a class="headerlink" href="#module-pygho.backend.utils" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="pygho.backend.utils.torch_scatter_reduce">
<span class="sig-prename descclassname"><span class="pre">pygho.backend.utils.</span></span><span class="sig-name descname"><span class="pre">torch_scatter_reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/pygho/backend/utils.html#torch_scatter_reduce"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pygho.backend.utils.torch_scatter_reduce" title="Link to this definition"></a></dt>
<dd><p>Applies a reduction operation to scatter elements from <cite>src</cite> to <cite>dim_size</cite>
locations based on the indices in <cite>ind</cite>.</p>
<p>This function is a wrapper for <cite>torch.Tensor.scatter_reduce_</cite> and is designed
to scatter elements from <cite>src</cite> to <cite>dim_size</cite> locations based on the specified
dimension <cite>dim</cite> and the indices in <cite>ind</cite>. The reduction operation is specified
by the <cite>aggr</cite> parameter, which can be ‘sum’, ‘mean’, ‘min’, ‘max’.</p>
<p>Args:</p>
<ul class="simple">
<li><p>dim (int): The dimension along which to scatter elements (only dim=0 is currently supported).</p></li>
<li><p>src (Tensor): The source tensor of shape (nnz, denseshape).</p></li>
<li><p>ind (LongTensor): The indices tensor of shape (nnz).</p></li>
<li><p>dim_size (int): The size of the target dimension for scattering.</p></li>
<li><p>aggr (str): The reduction operation to apply (‘sum’, ‘mean’, ‘min’, ‘max’, ‘mul’, ‘any’).</p></li>
</ul>
<p>Returns:</p>
<ul class="simple">
<li><p>Tensor: A tensor of shape (dim_size, denseshape) resulting from the scatter operation.</p></li>
</ul>
<p>Raises:</p>
<ul class="simple">
<li><p>AssertionError: If <cite>dim</cite> is not 0, or if <cite>ind</cite> is not 1-dimensional.</p></li>
</ul>
<p>Example:</p>
<dl class="simple">
<dt>::</dt><dd><p>src = torch.tensor([[1, 2], [4, 5], [7, 8], [9, 10]], dtype=torch.float)
ind = torch.tensor([2, 2, 0, 1], dtype=torch.long)
dim_size = 3
aggr = ‘sum’
result = torch_scatter_reduce(0, src, ind, dim_size, aggr)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pygho.backend">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pygho.backend" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../notes/introduction.html" class="btn btn-neutral float-left" title="Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hodata.html" class="btn btn-neutral float-right" title="pygho.hodata package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, GraphPKU.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>